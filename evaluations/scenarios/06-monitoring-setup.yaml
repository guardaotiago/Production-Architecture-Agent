name: "Full Observability Setup for Production Service"
description: >
  Setting up complete observability — metrics, logs, traces, alerting, SLOs,
  and dashboards — for a production service.  Validates that the monitoring
  phase produces all required artifacts, that the gate criteria are satisfied,
  and that an incident response plan is in place to close the SDLC loop.

phases_covered: [7]
project_type: "generic"

setup:
  - description: "Create a temporary project directory"
    command: "mktemp -d /tmp/eval-monitoring-XXXXXX"
  - description: "Initialise SDLC with all prior phases marked complete"
    command: |
      python $ORCHESTRATOR_ROOT/scripts/init_sdlc.py \
        --project-name "payments-service" --output-dir $WORK_DIR
      python -c "
      import json, pathlib
      p = pathlib.Path('$WORK_DIR/.sdlc/state.json')
      s = json.loads(p.read_text())
      for phase in ['requirements','development','cicd','testing','uat','deployment']:
          s['phases'][phase]['status'] = 'completed'
          s['phases'][phase]['gate_passed'] = True
      s['current_phase'] = 'monitoring'
      s['phases']['monitoring']['status'] = 'in_progress'
      p.write_text(json.dumps(s, indent=2))
      "
  - description: "Create basic project structure"
    command: "mkdir -p $WORK_DIR/src $WORK_DIR/docs $WORK_DIR/monitoring"

steps:
  - phase: "monitoring"
    action: "Define SLOs and error budgets"
    command: |
      cat > $WORK_DIR/docs/slo-definitions.md <<'EOF'
      # SLO Definitions — payments-service

      ## Availability SLO
      - Target: 99.9% uptime (measured over 30-day rolling window)
      - Error budget: 43.2 minutes/month
      - Measurement: ratio of successful HTTP responses (non-5xx) to total

      ## Latency SLO
      - Target: p99 < 500ms for /pay endpoint
      - Error budget: 0.1% of requests may exceed 500ms
      - Measurement: histogram of response times from load balancer logs

      ## Throughput SLO
      - Target: sustain 1000 req/s without degradation
      - Measurement: p99 latency stays under 500ms at 1000 req/s load
      EOF
    expected: "docs/slo-definitions.md created with availability, latency, throughput SLOs"

  - phase: "monitoring"
    action: "Create alerting rules configuration"
    command: |
      cat > $WORK_DIR/monitoring/alert-rules.yml <<'EOF'
      groups:
        - name: payments-service-alerts
          rules:
            - alert: HighErrorRate
              expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: "Error rate exceeds 5% on payments-service"

            - alert: HighLatency
              expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 0.5
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "p99 latency exceeds 500ms on payments-service"

            - alert: ServiceDown
              expr: up{job="payments-service"} == 0
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: "payments-service instance is down"
      EOF
    expected: "monitoring/alert-rules.yml created with HighErrorRate, HighLatency, ServiceDown"

  - phase: "monitoring"
    action: "Create an incident response plan"
    command: |
      cat > $WORK_DIR/docs/incident-response-plan.md <<'EOF'
      # Incident Response Plan

      ## Severity Levels
      | Level | Description | Response Time |
      |-------|-------------|---------------|
      | SEV1  | Service completely down | 15 minutes |
      | SEV2  | Degraded performance affecting >10% users | 30 minutes |
      | SEV3  | Minor issue, workaround available | 4 hours |

      ## Escalation Path
      1. On-call engineer receives alert via PagerDuty
      2. If not acknowledged in 10 min, escalate to team lead
      3. If SEV1, create incident channel and page SRE manager

      ## Postmortem Process
      - Blameless postmortem within 48 hours of SEV1/SEV2
      - Document timeline, root cause, action items
      - Track action items in the project backlog
      EOF
    expected: "docs/incident-response-plan.md created with severity levels and escalation"

  - phase: "monitoring"
    action: "Create a Grafana dashboard definition (JSON stub)"
    command: |
      cat > $WORK_DIR/monitoring/dashboard.json <<'EOF'
      {
        "dashboard": {
          "title": "payments-service Overview",
          "panels": [
            {"title": "Request Rate", "type": "graph", "targets": [{"expr": "rate(http_requests_total[5m])"}]},
            {"title": "Error Rate", "type": "graph", "targets": [{"expr": "rate(http_requests_total{status=~'5..'}[5m])"}]},
            {"title": "Latency p99", "type": "graph", "targets": [{"expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))"}]},
            {"title": "CPU Usage", "type": "graph", "targets": [{"expr": "process_cpu_seconds_total"}]}
          ]
        }
      }
      EOF
    expected: "monitoring/dashboard.json created with 4 panels"

  - phase: "monitoring"
    action: "Record monitoring configuration and dashboard creation in state"
    command: >
      python -c "
      import json, pathlib
      p = pathlib.Path('$WORK_DIR/.sdlc/state.json')
      s = json.loads(p.read_text())
      notes = s['phases']['monitoring']['notes']
      notes.append('Monitoring configured: Prometheus metrics + Grafana dashboards')
      notes.append('Dashboard created: payments-service Overview with 4 panels')
      p.write_text(json.dumps(s, indent=2))
      "
    expected: "Monitoring state notes contain configured and dashboard keywords"

  - phase: "monitoring"
    action: "Validate the monitoring gate"
    command: "python $ORCHESTRATOR_ROOT/scripts/gate_validator.py --phase monitoring --project-dir $WORK_DIR"
    expected: "Exit code 0 — all monitoring gate criteria pass"

  - phase: "monitoring"
    action: "Run full gate validation across all phases"
    command: "python $ORCHESTRATOR_ROOT/scripts/gate_validator.py --all --project-dir $WORK_DIR"
    expected: "Exit code 0 — every phase gate passes (prior phases were pre-completed)"

  - phase: "monitoring"
    action: "Check project health score after all phases complete"
    command: "python $ORCHESTRATOR_ROOT/scripts/project_health.py --project-dir $WORK_DIR --json"
    expected: "JSON output includes health_score > 0"

assertions:
  - description: "SLO document exists"
    type: "file_exists"
    target: "$WORK_DIR/docs/slo-definitions.md"
    expected: true

  - description: "Alert rules file exists"
    type: "file_exists"
    target: "$WORK_DIR/monitoring/alert-rules.yml"
    expected: true

  - description: "Incident response plan exists"
    type: "file_exists"
    target: "$WORK_DIR/docs/incident-response-plan.md"
    expected: true

  - description: "Monitoring gate passes"
    type: "exit_code"
    target: "python scripts/gate_validator.py --phase monitoring --project-dir $WORK_DIR"
    expected: 0

  - description: "Full --all gate validation passes"
    type: "exit_code"
    target: "python scripts/gate_validator.py --all --project-dir $WORK_DIR"
    expected: 0

tags: ["monitoring", "observability", "slo", "alerting", "incident-response", "grafana"]
